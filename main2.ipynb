{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import plot_roc_curve\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.decomposition import SparsePCA\n",
        "from collections import Counter\n",
        "from sklearn import preprocessing\n",
        "import re\n",
        "from wordcloud import WordCloud\n",
        "import string\n",
        "import nltk as nlp\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('True.csv')\n",
        "df2 = pd.read_csv('Fake.csv')\n",
        "df1['category']=1\n",
        "df2['category']=0\n",
        "df = pd.concat([df1, df2], axis=0,ignore_index=True)\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "sns.countplot(df.category)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum() # Checking for nan Values"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.title.count()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.subject.value_counts()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (12,8))\n",
        "sns.set(style = \"whitegrid\",font_scale = 1.2)\n",
        "chart = sns.countplot(x = \"subject\", hue = \"category\" , data = df)\n",
        "chart.set_xticklabels(chart.get_xticklabels(),rotation=90)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'] + \" \" + df['title']\n",
        "del df['title']\n",
        "del df['subject']\n",
        "del df['date']\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "#Removing the square brackets\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub('\\[[^]]*\\]', '', text)\n",
        "# Removing URL's\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'http\\S+', '', text)\n",
        "#Removing the stopwords from text\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "#Removing the noisy text\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text\n",
        "#Apply function on review column\n",
        "df['text']=df['text'].apply(denoise_text)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,20)) # Text that is not Fake\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(df[df.category == 1].text))\n",
        "plt.imshow(wc , interpolation = 'bilinear')\n",
        "plt.title('WORDCLOUD FOR REAL TEXT')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (20,20)) # Text that is Fake\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(df[df.category == 0].text))\n",
        "plt.imshow(wc , interpolation = 'bilinear')\n",
        "plt.title('WORDCLOUD FOR FAKE TEXT')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,8))\n",
        "text_len=df[df['category']==1]['text'].str.len()\n",
        "ax1.hist(text_len,color='red')\n",
        "ax1.set_title('Original text')\n",
        "text_len=df[df['category']==0]['text'].str.len()\n",
        "ax2.hist(text_len,color='green')\n",
        "ax2.set_title('Fake text')\n",
        "fig.suptitle('Characters in texts')\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,8))\n",
        "text_len=df[df['category']==1]['text'].str.split().map(lambda x: len(x))\n",
        "ax1.hist(text_len,color='red')\n",
        "ax1.set_title('Original text')\n",
        "text_len=df[df['category']==0]['text'].str.split().map(lambda x: len(x))\n",
        "ax2.hist(text_len,color='green')\n",
        "ax2.set_title('Fake text')\n",
        "fig.suptitle('Words in texts')\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(20,10))\n",
        "word=df[df['category']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\n",
        "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\n",
        "ax1.set_title('Original text')\n",
        "word=df[df['category']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\n",
        "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\n",
        "ax2.set_title('Fake text')\n",
        "fig.suptitle('Average word length in each text')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corpus(text):\n",
        "    words = []\n",
        "    for i in text:\n",
        "        for j in i.split():\n",
        "            words.append(j.strip())\n",
        "    return words\n",
        "corpus = get_corpus(df.text)\n",
        "corpus[:5]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counter = Counter(corpus)\n",
        "most_common = counter.most_common(10)\n",
        "most_common = dict(most_common)\n",
        "most_common"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "def get_top_text_ngrams(corpus, n, g):\n",
        "    vec = CountVectorizer(ngram_range=(g, g)).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "    return words_freq[:n]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,9))\n",
        "most_common_uni = get_top_text_ngrams(df.text,10,1)\n",
        "most_common_uni = dict(most_common_uni)\n",
        "sns.barplot(x=list(most_common_uni.values()),y=list(most_common_uni.keys()))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,9))\n",
        "most_common_bi = get_top_text_ngrams(df.text,10,2)\n",
        "most_common_bi = dict(most_common_bi)\n",
        "sns.barplot(x=list(most_common_bi.values()),y=list(most_common_bi.keys()))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (16,9))\n",
        "most_common_tri = get_top_text_ngrams(df.text,10,3)\n",
        "most_common_tri = dict(most_common_tri)\n",
        "sns.barplot(x=list(most_common_tri.values()),y=list(most_common_tri.keys()))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('True.csv')\n",
        "df2 = pd.read_csv('Fake.csv')\n",
        "df1['category']=1\n",
        "df2['category']=0\n",
        "df = pd.concat([df1, df2], axis=0,ignore_index=True)\n",
        "df.info()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target = ['Fake', 'True',]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "sns.countplot(df.category)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'] + \" \" + df['title']\n",
        "del df['title']\n",
        "del df['subject']\n",
        "del df['date']\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "stop"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for letter in '1234567890.(/ÀÈÌÒÙàèìòùÁÉÍÓÚÝáéíóúýÂÊÎÔÛâêîôûÃÑÕãñõÄËÏÖÜŸäëïöüÿ':\n",
        "    df[\"text\"] = df[\"text\"].str.replace(letter,'')\n",
        "\n",
        "english_punctuations = string.punctuation\n",
        "punctuations_list = english_punctuations + english_punctuations\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)\n",
        "\n",
        "def remove_repeating_char(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "def processPost(text:str):\n",
        "    text = re.sub('@[^\\s]+', ' ', text)\n",
        "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',text)\n",
        "\n",
        "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
        "\n",
        "    text= remove_punctuations(text)\n",
        "    text=remove_repeating_char(text)\n",
        "    text=text.lower()\n",
        "    return text\n",
        "\n",
        "df=df.sample(frac=0.6, replace=True, random_state=1)\n",
        "df[\"text\"] = df[\"text\"].apply(processPost)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_list = stopwords.words('english')\n",
        "df['text']=df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "#df[\"text\"]=df[\"text\"].apply(lambda x: [item for item in x if item not in stopwords_list])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'][0]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizer = RegexpTokenizer(r'\\w+')\n",
        "#df[\"text\"] = df[\"text\"].apply(tokenizer.tokenize)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df['text'] = df['text'].apply(lambda x: ' '.join(map(str, x)))\n",
        "#df.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = df.iloc[0][0]\n",
        "text\n",
        "w_tokenizer = nlp.tokenize.WhitespaceTokenizer()\n",
        "lemmatizer = nlp.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
        "\n",
        "df['text'] = df['text'].apply(lemmatize_text)\n",
        "df['text'] = df['text'].apply(lambda x: ' '.join(map(str, x)))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X=df['text']\n",
        "y=df['category']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.45, random_state=65)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conf_matrix(actual, predicted):\n",
        "    cm = confusion_matrix(actual, predicted)\n",
        "    sns.heatmap(cm, xticklabels=['predicted_negative', 'predicted_positive'],\n",
        "                yticklabels=['actual_negative', 'actual_positive'], annot=True,\n",
        "                fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
        "\n",
        "    true_neg, false_pos = cm[0]\n",
        "    false_neg, true_pos = cm[1]\n",
        "\n",
        "    accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
        "    precision = round((true_pos) / (true_pos + false_pos),3)\n",
        "    recall = round((true_pos) / (true_pos + false_neg),3)\n",
        "    f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
        "\n",
        "    cm_results = [accuracy, precision, recall, f1]\n",
        "    return cm_results\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv1 = CountVectorizer(stop_words='english')\n",
        "X_train_cv1 = cv1.fit_transform(X_train)\n",
        "X_test_cv1  = cv1.transform(X_test)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.DataFrame(X_train_cv1.toarray(), columns=cv1.get_feature_names())\n",
        "pd.DataFrame(X_train_cv1.toarray(), columns=cv1.get_feature_names()).head()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf1 = TfidfVectorizer(stop_words='english')\n",
        "\n",
        "X_train_tfidf1 = tfidf1.fit_transform(X_train)\n",
        "X_test_tfidf1  = tfidf1.transform(X_test)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the objects\n",
        "lr_cv1 = LogisticRegression()\n",
        "knn_cv1 = KNeighborsClassifier(n_neighbors=2)\n",
        "rf_cv1 = RandomForestClassifier(n_estimators = 100, criterion = 'entropy')\n",
        "cv1_dict = {0: 'Logistic Regression', 1:'KNN', 2:'Random Forest'}\n",
        "cv1_models=[lr_cv1,knn_cv1,rf_cv1]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_cv1.fit(X_train_cv1, y_train)\n",
        "y_pred_cv1=lr_cv1.predict(X_test_cv1)\n",
        "cm1 = conf_matrix(y_test, y_pred_cv1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_cv1.fit(X_train_cv1, y_train)\n",
        "y_pred_cv1=knn_cv1.predict(X_test_cv1)\n",
        "cm2 = conf_matrix(y_test, y_pred_cv1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_cv1.fit(X_train_cv1, y_train)\n",
        "y_pred_cv1=rf_cv1.predict(X_test_cv1)\n",
        "cm3 = conf_matrix(y_test, y_pred_cv1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_tfidf1 = LogisticRegression()\n",
        "knn_tfidf1 = KNeighborsClassifier(n_neighbors=2)\n",
        "rf_tfidf1 = RandomForestClassifier(n_estimators = 100, criterion = 'entropy')\n",
        "tfidf1_dict = {0: 'Logistic Regression', 1:'KNN', 2:'Random Forest'}\n",
        "tfidf1_models=[lr_tfidf1,knn_tfidf1,rf_tfidf1]\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_tfidf1.fit(X_train_tfidf1, y_train)\n",
        "y_pred_tfidf1=lr_tfidf1.predict(X_test_tfidf1)\n",
        "cm4 = conf_matrix(y_test, y_pred_tfidf1)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn_tfidf1.fit(X_train_tfidf1, y_train)\n",
        "y_pred_tfidf1=knn_tfidf1.predict(X_test_tfidf1)\n",
        "cm5 = conf_matrix(y_test, y_pred_tfidf1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_tfidf1.fit(X_train_tfidf1, y_train)\n",
        "y_pred_tfidf1=rf_tfidf1.predict(X_test_tfidf1)\n",
        "cm6 = conf_matrix(y_test, y_pred_tfidf1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=10) # k=10, split the data into 10 equal parts\n",
        "xyz=[]\n",
        "accuracy=[]\n",
        "std=[]\n",
        "classifiers=['Logistic Regression','KNN','Random Forest']\n",
        "models=[LogisticRegression(),\n",
        "        KNeighborsClassifier(n_neighbors=2),\n",
        "        RandomForestClassifier(n_estimators = 100, criterion = 'entropy')]\n",
        "def cval(X,y):\n",
        "    for i in models:\n",
        "        model = i\n",
        "        cv_result = cross_val_score(model,X,y, cv = kfold,scoring = \"accuracy\")\n",
        "        cv_result = cv_result\n",
        "        xyz.append(cv_result.mean())\n",
        "        std.append(cv_result.std())\n",
        "        accuracy.append(cv_result)\n",
        "\n",
        "cval(X_train_cv1,y_train)\n",
        "cval(X_train_tfidf1,y_train)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#models_dataframe['CV Mean']\n",
        "classifiers=['LogRegcv1','KNNcv1','RandForcv1','LogRegtfidf1','KNNtfidf1','RandFortfidf1']\n",
        "models_dataframe=pd.DataFrame({'CV Mean':xyz},index=classifiers)\n",
        "models_dataframe"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "disp = plot_roc_curve(lr_cv1, X_test_cv1, y_test)\n",
        "plot_roc_curve(knn_cv1, X_test_cv1, y_test, ax=disp.ax_)\n",
        "plot_roc_curve(rf_cv1, X_test_cv1, y_test, ax=disp.ax_)\n",
        "plot_roc_curve(lr_tfidf1, X_test_tfidf1, y_test, ax=disp.ax_)\n",
        "plot_roc_curve(knn_tfidf1, X_test_tfidf1, y_test, ax=disp.ax_)\n",
        "plot_roc_curve(rf_tfidf1, X_test_tfidf1, y_test, ax=disp.ax_)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame(list(zip(cm1,cm2,cm3,cm4,cm5,cm6)))\n",
        "results = results.set_index([['Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
        "results.columns = ['LogRegcv1','KNNcv1','RandForcv1','LogRegtfidf1','KNNtfidf1','RandFortfidf1']\n",
        "results.transpose()['Avg']=(results.transpose()['Accuracy']+results.transpose()['Precision']+results.transpose()['Recall']+results.transpose()['F1 Score'])/4"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results.transpose().sort_values(['Accuracy','F1 Score','Precision','Recall'],ascending=False)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([models_dataframe,results.transpose()],axis =1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_text(text:str):\n",
        "    text = [processPost(text)]\n",
        "    text = cv1.transform(text)\n",
        "    print(target[lr_cv1.predict(text)[0]])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_text('Trump hates obama')\n",
        "predict_text('Trump is poor')\n",
        "|"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}